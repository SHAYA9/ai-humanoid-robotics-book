{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/ai-humanoid-robotics-book/docs","tagsPath":"/ai-humanoid-robotics-book/docs/tags","isLast":true,"routePriority":-1,"sidebarFilePath":"C:\\Users\\SHAYAN\\Desktop\\New folder\\ai-humanoid-robotics-book\\sidebars.ts","contentPath":"C:\\Users\\SHAYAN\\Desktop\\New folder\\ai-humanoid-robotics-book\\docs","docs":[{"id":"hardware-guide","title":"Hardware Guide","description":"This guide provides detailed specifications and recommendations for the hardware used in this course. While we provide a cloud alternative, having access to physical hardware will provide the best learning experience.","source":"@site/docs/hardware-guide.md","sourceDirName":".","slug":"/hardware-guide","permalink":"/ai-humanoid-robotics-book/docs/hardware-guide","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Hardware Guide"},"sidebar":"tutorialSidebar","previous":{"title":"Learning Path","permalink":"/ai-humanoid-robotics-book/docs/learning-path"},"next":{"title":"Module 1: The Robotic Nervous System (ROS 2)","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/overview"}},{"id":"intro","title":"Introduction to Physical AI & Humanoid Robotics","description":"Bridging the gap between digital brain and physical body.","source":"@site/docs/intro.md","sourceDirName":".","slug":"/intro","permalink":"/ai-humanoid-robotics-book/docs/intro","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Introduction to Physical AI & Humanoid Robotics"},"sidebar":"tutorialSidebar","next":{"title":"Prerequisites","permalink":"/ai-humanoid-robotics-book/docs/prerequisites"}},{"id":"learning-path","title":"Learning Path","description":"This course is structured as a 13-week program. Each week builds on the previous one, so it is recommended to follow the schedule in order.","source":"@site/docs/learning-path.md","sourceDirName":".","slug":"/learning-path","permalink":"/ai-humanoid-robotics-book/docs/learning-path","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Learning Path"},"sidebar":"tutorialSidebar","previous":{"title":"Prerequisites","permalink":"/ai-humanoid-robotics-book/docs/prerequisites"},"next":{"title":"Hardware Guide","permalink":"/ai-humanoid-robotics-book/docs/hardware-guide"}},{"id":"module-1-ros2/nodes-topics-services","title":"Nodes, Topics, and Services","description":"Now that we have a high-level overview of the ROS 2 architecture, let's dive deeper into the core components that make it work: nodes, topics, services, and actions.","source":"@site/docs/module-1-ros2/nodes-topics-services.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/nodes-topics-services","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/nodes-topics-services","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Nodes, Topics, and Services"},"sidebar":"tutorialSidebar","previous":{"title":"ROS 2 Architecture","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/ros2-architecture"},"next":{"title":"rclpy - Python Agents for ROS 2","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/rclpy-python-agents"}},{"id":"module-1-ros2/overview","title":"Module 1: The Robotic Nervous System (ROS 2)","description":"Welcome to Module 1. In this section, we will explore the Robot Operating System (ROS 2), the middleware that will serve as the nervous system for our humanoid robots.","source":"@site/docs/module-1-ros2/overview.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/overview","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/overview","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Module 1: The Robotic Nervous System (ROS 2)"},"sidebar":"tutorialSidebar","previous":{"title":"Hardware Guide","permalink":"/ai-humanoid-robotics-book/docs/hardware-guide"},"next":{"title":"ROS 2 Architecture","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/ros2-architecture"}},{"id":"module-1-ros2/practical-1-ros2-setup","title":"Practical 1: ROS 2 Setup","description":"In this practical, we will set up a ROS 2 workspace, create a package, and build the talker and listener nodes we wrote in the rclpy section.","source":"@site/docs/module-1-ros2/practical-1-ros2-setup.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/practical-1-ros2-setup","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/practical-1-ros2-setup","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"title":"Practical 1: ROS 2 Setup"},"sidebar":"tutorialSidebar","previous":{"title":"URDF for Humanoids","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/urdf-humanoids"},"next":{"title":"Module 2: The Digital Twin (Gazebo & Unity)","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/overview"}},{"id":"module-1-ros2/rclpy-python-agents","title":"rclpy - Python Agents for ROS 2","description":"rclpy is the official Python client library for ROS 2. It provides a high-level, Pythonic interface to the ROS 2 ecosystem, allowing you to write your own ROS 2 nodes, publishers, subscribers, and more.","source":"@site/docs/module-1-ros2/rclpy-python-agents.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/rclpy-python-agents","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/rclpy-python-agents","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"rclpy - Python Agents for ROS 2"},"sidebar":"tutorialSidebar","previous":{"title":"Nodes, Topics, and Services","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/nodes-topics-services"},"next":{"title":"URDF for Humanoids","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/urdf-humanoids"}},{"id":"module-1-ros2/ros2-architecture","title":"ROS 2 Architecture","description":"The architecture of ROS 2 is designed to be a flexible, scalable, and robust platform for robotics. It is a significant evolution from ROS 1, built to support a wider range of applications, from small, single-board computers to large, multi-robot systems.","source":"@site/docs/module-1-ros2/ros2-architecture.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/ros2-architecture","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/ros2-architecture","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"ROS 2 Architecture"},"sidebar":"tutorialSidebar","previous":{"title":"Module 1: The Robotic Nervous System (ROS 2)","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/overview"},"next":{"title":"Nodes, Topics, and Services","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/nodes-topics-services"}},{"id":"module-1-ros2/urdf-humanoids","title":"URDF for Humanoids","description":"The Unified Robot Description Format (URDF) is an XML format for representing a robot model. In ROS 2, URDF is the standard way to describe the physical structure of a robot, including its links, joints, sensors, and visual appearance.","source":"@site/docs/module-1-ros2/urdf-humanoids.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/urdf-humanoids","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/urdf-humanoids","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"URDF for Humanoids"},"sidebar":"tutorialSidebar","previous":{"title":"rclpy - Python Agents for ROS 2","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/rclpy-python-agents"},"next":{"title":"Practical 1: ROS 2 Setup","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/practical-1-ros2-setup"}},{"id":"module-2-simulation/environment-building","title":"Environment Building","description":"The environment is just as important as the robot itself in a simulation. A well-crafted environment allows for testing a wide range of scenarios and ensures that the simulation is a meaningful representation of the real world.","source":"@site/docs/module-2-simulation/environment-building.md","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/environment-building","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/environment-building","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"Environment Building"},"sidebar":"tutorialSidebar","previous":{"title":"Sensor Simulation","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/sensor-simulation"},"next":{"title":"Practical 2: Digital Twin","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/practical-2-digital-twin"}},{"id":"module-2-simulation/gazebo-physics","title":"Gazebo Physics","description":"Gazebo is a powerful, open-source 3D robotics simulator. At its core is a robust physics engine that allows you to simulate the dynamics of robots and their interactions with the environment with a high degree of realism.","source":"@site/docs/module-2-simulation/gazebo-physics.md","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/gazebo-physics","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/gazebo-physics","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Gazebo Physics"},"sidebar":"tutorialSidebar","previous":{"title":"Module 2: The Digital Twin (Gazebo & Unity)","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/overview"},"next":{"title":"Unity Rendering","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/unity-rendering"}},{"id":"module-2-simulation/overview","title":"Module 2: The Digital Twin (Gazebo & Unity)","description":"Welcome to Module 2. In this section, we will explore the concept of the digital twin and learn how to use powerful simulation tools like Gazebo and Unity to create realistic virtual environments for our robots.","source":"@site/docs/module-2-simulation/overview.md","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/overview","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/overview","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Module 2: The Digital Twin (Gazebo & Unity)"},"sidebar":"tutorialSidebar","previous":{"title":"Practical 1: ROS 2 Setup","permalink":"/ai-humanoid-robotics-book/docs/module-1-ros2/practical-1-ros2-setup"},"next":{"title":"Gazebo Physics","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/gazebo-physics"}},{"id":"module-2-simulation/practical-2-digital-twin","title":"Practical 2: Digital Twin","description":"In this practical exercise, we'll bring together the concepts from this module to create a digital twin of a simple robot in a simulated environment. A digital twin is a virtual model of a physical object, used to simulate its behavior and monitor its state.","source":"@site/docs/module-2-simulation/practical-2-digital-twin.md","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/practical-2-digital-twin","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/practical-2-digital-twin","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"title":"Practical 2: Digital Twin"},"sidebar":"tutorialSidebar","previous":{"title":"Environment Building","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/environment-building"},"next":{"title":"Overview","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/overview"}},{"id":"module-2-simulation/sensor-simulation","title":"Sensor Simulation","description":"A robot is only as good as its perception of the world, which is why accurate sensor simulation is critical for developing and testing robotics software. Simulators like Gazebo and Unity provide models for a wide range of common sensors.","source":"@site/docs/module-2-simulation/sensor-simulation.md","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/sensor-simulation","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/sensor-simulation","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Sensor Simulation"},"sidebar":"tutorialSidebar","previous":{"title":"Unity Rendering","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/unity-rendering"},"next":{"title":"Environment Building","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/environment-building"}},{"id":"module-2-simulation/unity-rendering","title":"Unity Rendering","description":"While Gazebo is prized for its physics simulation, Unity stands out for its cutting-edge graphics and rendering capabilities. This makes it an excellent choice for tasks where visual realism is paramount, such as generating synthetic data for training computer vision models or creating compelling user interfaces for robot control.","source":"@site/docs/module-2-simulation/unity-rendering.md","sourceDirName":"module-2-simulation","slug":"/module-2-simulation/unity-rendering","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/unity-rendering","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Unity Rendering"},"sidebar":"tutorialSidebar","previous":{"title":"Gazebo Physics","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/gazebo-physics"},"next":{"title":"Sensor Simulation","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/sensor-simulation"}},{"id":"module-3-isaac/isaac-ros","title":"Isaac ROS","description":"Isaac ROS is a collection of ROS 2 packages that are optimized to run on NVIDIA's Jetson and GPU platforms. These packages provide hardware acceleration for common robotics tasks, enabling real-time performance that would be difficult to achieve with a CPU alone.","source":"@site/docs/module-3-isaac/isaac-ros.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/isaac-ros","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/isaac-ros","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Isaac ROS"},"sidebar":"tutorialSidebar","previous":{"title":"Isaac Sim","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/isaac-sim"},"next":{"title":"vSLAM Navigation","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/vslam-navigation"}},{"id":"module-3-isaac/isaac-sim","title":"Isaac Sim","description":"Isaac Sim is NVIDIA's robotics simulation platform, built on top of their Omniverse 3D collaboration and simulation framework. It offers a level of realism and performance that is a significant step up from traditional simulators like Gazebo.","source":"@site/docs/module-3-isaac/isaac-sim.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/isaac-sim","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/isaac-sim","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Isaac Sim"},"sidebar":"tutorialSidebar","previous":{"title":"Overview","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/overview"},"next":{"title":"Isaac ROS","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/isaac-ros"}},{"id":"module-3-isaac/nav2-bipedal","title":"Nav2 for Bipedal Robots","description":"The ROS 2 Navigation Stack (Nav2) is a powerful and flexible framework for autonomous navigation. While it was originally designed for wheeled robots, it can be adapted to work with more complex platforms like bipedal robots (humanoids).","source":"@site/docs/module-3-isaac/nav2-bipedal.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/nav2-bipedal","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/nav2-bipedal","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"Nav2 for Bipedal Robots"},"sidebar":"tutorialSidebar","previous":{"title":"vSLAM Navigation","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/vslam-navigation"},"next":{"title":"Practical 3: Perception","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/practical-3-perception"}},{"id":"module-3-isaac/overview","title":"Overview","description":"Welcome to Module 3! In this section, we'll dive into the NVIDIA Isaac ecosystem, a powerful platform for developing and deploying AI-powered robots. Isaac provides a suite of tools that accelerate the entire robotics workflow, from simulation to deployment.","source":"@site/docs/module-3-isaac/overview.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/overview","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/overview","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Overview"},"sidebar":"tutorialSidebar","previous":{"title":"Practical 2: Digital Twin","permalink":"/ai-humanoid-robotics-book/docs/module-2-simulation/practical-2-digital-twin"},"next":{"title":"Isaac Sim","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/isaac-sim"}},{"id":"module-3-isaac/practical-3-perception","title":"Practical 3: Perception","description":"In this practical exercise, you'll get hands-on experience with the Isaac ROS perception packages. You'll set up a simple perception pipeline in Isaac Sim and visualize the results in RViz.","source":"@site/docs/module-3-isaac/practical-3-perception.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/practical-3-perception","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/practical-3-perception","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"title":"Practical 3: Perception"},"sidebar":"tutorialSidebar","previous":{"title":"Nav2 for Bipedal Robots","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/nav2-bipedal"},"next":{"title":"Overview","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/overview"}},{"id":"module-3-isaac/vslam-navigation","title":"vSLAM Navigation","description":"Visual SLAM (vSLAM) is a technique for Simultaneous Localization and Mapping that uses camera data as its primary input. The Isaac ROS vSLAM package is a powerful, GPU-accelerated implementation that can provide robust and accurate real-time localization and mapping for robots.","source":"@site/docs/module-3-isaac/vslam-navigation.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/vslam-navigation","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/vslam-navigation","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"vSLAM Navigation"},"sidebar":"tutorialSidebar","previous":{"title":"Isaac ROS","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/isaac-ros"},"next":{"title":"Nav2 for Bipedal Robots","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/nav2-bipedal"}},{"id":"module-4-vla/capstone-project","title":"Capstone Project: The Autonomous Humanoid","description":"Final project integrating all modules: Voice-controlled humanoid with vision, planning, and autonomous navigation","source":"@site/docs/module-4-vla/capstone-project.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/capstone-project","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/capstone-project","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"capstone","permalink":"/ai-humanoid-robotics-book/docs/tags/capstone"},{"inline":true,"label":"vla","permalink":"/ai-humanoid-robotics-book/docs/tags/vla"},{"inline":true,"label":"autonomous","permalink":"/ai-humanoid-robotics-book/docs/tags/autonomous"},{"inline":true,"label":"humanoid","permalink":"/ai-humanoid-robotics-book/docs/tags/humanoid"},{"inline":true,"label":"integration","permalink":"/ai-humanoid-robotics-book/docs/tags/integration"}],"version":"current","frontMatter":{"id":"capstone-project","title":"Capstone Project: The Autonomous Humanoid","sidebar_label":"Capstone: Autonomous Humanoid","description":"Final project integrating all modules: Voice-controlled humanoid with vision, planning, and autonomous navigation","tags":["capstone","vla","autonomous","humanoid","integration"]},"sidebar":"tutorialSidebar","previous":{"title":"Multimodal Integration","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/multimodal-integration"},"next":{"title":"Practical: Autonomous Humanoid","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/practical-4-autonomous-humanoid"}},{"id":"module-4-vla/llm-planning","title":"LLM Planning","description":"Large Language Models (LLMs) like GPT-4 have demonstrated remarkable abilities in reasoning and planning. This has opened up exciting new possibilities for using LLMs as the \"brain\" of a robot, responsible for high-level planning and decision-making.","source":"@site/docs/module-4-vla/llm-planning.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/llm-planning","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/llm-planning","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"LLM Planning"},"sidebar":"tutorialSidebar","previous":{"title":"Whisper Voice Control","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/whisper-voice"},"next":{"title":"Multimodal Integration","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/multimodal-integration"}},{"id":"module-4-vla/multimodal-integration","title":"Multimodal Integration","description":"The real power of Vision-Language-Action (VLA) models comes from their ability to process and understand information from multiple modalities simultaneously. This is known as multimodal integration.","source":"@site/docs/module-4-vla/multimodal-integration.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/multimodal-integration","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/multimodal-integration","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Multimodal Integration"},"sidebar":"tutorialSidebar","previous":{"title":"LLM Planning","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/llm-planning"},"next":{"title":"Capstone: Autonomous Humanoid","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/capstone-project"}},{"id":"module-4-vla/overview","title":"Overview","description":"Welcome to Module 4! This is where we bring everything together to explore the exciting frontier of Vision-Language-Action (VLA) models in robotics. VLAs are AI models that can understand and respond to natural language commands, perceive the world through vision, and take actions to accomplish tasks.","source":"@site/docs/module-4-vla/overview.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/overview","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/overview","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Overview"},"sidebar":"tutorialSidebar","previous":{"title":"Practical 3: Perception","permalink":"/ai-humanoid-robotics-book/docs/module-3-isaac/practical-3-perception"},"next":{"title":"Whisper Voice Control","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/whisper-voice"}},{"id":"module-4-vla/practical-4-autonomous-humanoid","title":"Practical 4: Building Your Autonomous Humanoid","description":"Step-by-step implementation guide for the capstone autonomous humanoid robot","source":"@site/docs/module-4-vla/practical-4-autonomous-humanoid.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/practical-4-autonomous-humanoid","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/practical-4-autonomous-humanoid","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"practical","permalink":"/ai-humanoid-robotics-book/docs/tags/practical"},{"inline":true,"label":"implementation","permalink":"/ai-humanoid-robotics-book/docs/tags/implementation"},{"inline":true,"label":"autonomous","permalink":"/ai-humanoid-robotics-book/docs/tags/autonomous"},{"inline":true,"label":"humanoid","permalink":"/ai-humanoid-robotics-book/docs/tags/humanoid"},{"inline":true,"label":"ros2","permalink":"/ai-humanoid-robotics-book/docs/tags/ros-2"}],"version":"current","frontMatter":{"id":"practical-4-autonomous-humanoid","title":"Practical 4: Building Your Autonomous Humanoid","sidebar_label":"Practical: Autonomous Humanoid","description":"Step-by-step implementation guide for the capstone autonomous humanoid robot","tags":["practical","implementation","autonomous","humanoid","ros2"]},"sidebar":"tutorialSidebar","previous":{"title":"Capstone: Autonomous Humanoid","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/capstone-project"},"next":{"title":"Hardware Setup","permalink":"/ai-humanoid-robotics-book/docs/resources/hardware-setup"}},{"id":"module-4-vla/whisper-voice","title":"Whisper Voice Control","description":"Whisper is a state-of-the-art automatic speech recognition (ASR) system developed by OpenAI. It's incredibly versatile and can transcribe spoken language from a wide range of audio inputs, making it an excellent choice for adding voice control to a robot.","source":"@site/docs/module-4-vla/whisper-voice.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/whisper-voice","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/whisper-voice","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Whisper Voice Control"},"sidebar":"tutorialSidebar","previous":{"title":"Overview","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/overview"},"next":{"title":"LLM Planning","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/llm-planning"}},{"id":"prerequisites","title":"Prerequisites","description":"To successfully complete this course, you will need a combination of hardware and software. We have designed the curriculum to be as accessible as possible, with a cloud-based lab alternative for those who do not have access to the recommended hardware.","source":"@site/docs/prerequisites.md","sourceDirName":".","slug":"/prerequisites","permalink":"/ai-humanoid-robotics-book/docs/prerequisites","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Prerequisites"},"sidebar":"tutorialSidebar","previous":{"title":"Introduction","permalink":"/ai-humanoid-robotics-book/docs/intro"},"next":{"title":"Learning Path","permalink":"/ai-humanoid-robotics-book/docs/learning-path"}},{"id":"resources/assessments","title":"Assessments & Grading","description":"Complete assessment structure, rubrics, and evaluation criteria for Physical AI course","source":"@site/docs/resources/assessments.md","sourceDirName":"resources","slug":"/resources/assessments","permalink":"/ai-humanoid-robotics-book/docs/resources/assessments","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"assessments","permalink":"/ai-humanoid-robotics-book/docs/tags/assessments"},{"inline":true,"label":"grading","permalink":"/ai-humanoid-robotics-book/docs/tags/grading"},{"inline":true,"label":"rubrics","permalink":"/ai-humanoid-robotics-book/docs/tags/rubrics"},{"inline":true,"label":"projects","permalink":"/ai-humanoid-robotics-book/docs/tags/projects"},{"inline":true,"label":"evaluation","permalink":"/ai-humanoid-robotics-book/docs/tags/evaluation"}],"version":"current","frontMatter":{"id":"assessments","title":"Assessments & Grading","sidebar_label":"Assessments","description":"Complete assessment structure, rubrics, and evaluation criteria for Physical AI course","tags":["assessments","grading","rubrics","projects","evaluation"]},"sidebar":"tutorialSidebar","previous":{"title":"Cloud Lab","permalink":"/ai-humanoid-robotics-book/docs/resources/cloud-lab"},"next":{"title":"References","permalink":"/ai-humanoid-robotics-book/docs/resources/references"}},{"id":"resources/cloud-lab","title":"Cloud Lab Setup: The Virtual Robotics Lab","description":"Complete guide to setting up your cloud-based robotics development environment","source":"@site/docs/resources/cloud-lab.md","sourceDirName":"resources","slug":"/resources/cloud-lab","permalink":"/ai-humanoid-robotics-book/docs/resources/cloud-lab","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"cloud","permalink":"/ai-humanoid-robotics-book/docs/tags/cloud"},{"inline":true,"label":"aws","permalink":"/ai-humanoid-robotics-book/docs/tags/aws"},{"inline":true,"label":"azure","permalink":"/ai-humanoid-robotics-book/docs/tags/azure"},{"inline":true,"label":"gpu","permalink":"/ai-humanoid-robotics-book/docs/tags/gpu"},{"inline":true,"label":"remote","permalink":"/ai-humanoid-robotics-book/docs/tags/remote"},{"inline":true,"label":"simulation","permalink":"/ai-humanoid-robotics-book/docs/tags/simulation"}],"version":"current","frontMatter":{"id":"cloud-lab","title":"Cloud Lab Setup: The Virtual Robotics Lab","sidebar_label":"Cloud Lab","description":"Complete guide to setting up your cloud-based robotics development environment","tags":["cloud","aws","azure","gpu","remote","simulation"]},"sidebar":"tutorialSidebar","previous":{"title":"Hardware Setup","permalink":"/ai-humanoid-robotics-book/docs/resources/hardware-setup"},"next":{"title":"Assessments","permalink":"/ai-humanoid-robotics-book/docs/resources/assessments"}},{"id":"resources/faq","title":"Frequently Asked Questions (FAQ)","description":"Common questions and answers about Physical AI & Humanoid Robotics course","source":"@site/docs/resources/faq.md","sourceDirName":"resources","slug":"/resources/faq","permalink":"/ai-humanoid-robotics-book/docs/resources/faq","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"faq","permalink":"/ai-humanoid-robotics-book/docs/tags/faq"},{"inline":true,"label":"questions","permalink":"/ai-humanoid-robotics-book/docs/tags/questions"},{"inline":true,"label":"help","permalink":"/ai-humanoid-robotics-book/docs/tags/help"},{"inline":true,"label":"troubleshooting","permalink":"/ai-humanoid-robotics-book/docs/tags/troubleshooting"}],"version":"current","frontMatter":{"id":"faq","title":"Frequently Asked Questions (FAQ)","sidebar_label":"FAQ","description":"Common questions and answers about Physical AI & Humanoid Robotics course","tags":["faq","questions","help","troubleshooting"]},"sidebar":"tutorialSidebar","previous":{"title":"References","permalink":"/ai-humanoid-robotics-book/docs/resources/references"},"next":{"title":"Glossary","permalink":"/ai-humanoid-robotics-book/docs/resources/glossary"}},{"id":"resources/glossary","title":"Glossary of Terms","description":"Comprehensive glossary of terms used in Physical AI and Humanoid Robotics","source":"@site/docs/resources/glossary.md","sourceDirName":"resources","slug":"/resources/glossary","permalink":"/ai-humanoid-robotics-book/docs/resources/glossary","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"glossary","permalink":"/ai-humanoid-robotics-book/docs/tags/glossary"},{"inline":true,"label":"terminology","permalink":"/ai-humanoid-robotics-book/docs/tags/terminology"},{"inline":true,"label":"definitions","permalink":"/ai-humanoid-robotics-book/docs/tags/definitions"},{"inline":true,"label":"robotics","permalink":"/ai-humanoid-robotics-book/docs/tags/robotics"},{"inline":true,"label":"ai","permalink":"/ai-humanoid-robotics-book/docs/tags/ai"}],"version":"current","frontMatter":{"id":"glossary","title":"Glossary of Terms","sidebar_label":"Glossary","description":"Comprehensive glossary of terms used in Physical AI and Humanoid Robotics","tags":["glossary","terminology","definitions","robotics","ai"]},"sidebar":"tutorialSidebar","previous":{"title":"FAQ","permalink":"/ai-humanoid-robotics-book/docs/resources/faq"}},{"id":"resources/hardware-setup","title":"Hardware Setup Guide: Building Your Physical AI Lab","description":"Complete hardware guide for Physical AI & Humanoid Robotics - From budget to premium setups","source":"@site/docs/resources/hardware-setup.md","sourceDirName":"resources","slug":"/resources/hardware-setup","permalink":"/ai-humanoid-robotics-book/docs/resources/hardware-setup","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"hardware","permalink":"/ai-humanoid-robotics-book/docs/tags/hardware"},{"inline":true,"label":"setup","permalink":"/ai-humanoid-robotics-book/docs/tags/setup"},{"inline":true,"label":"guide","permalink":"/ai-humanoid-robotics-book/docs/tags/guide"},{"inline":true,"label":"robotics","permalink":"/ai-humanoid-robotics-book/docs/tags/robotics"},{"inline":true,"label":"nvidia","permalink":"/ai-humanoid-robotics-book/docs/tags/nvidia"},{"inline":true,"label":"jetson","permalink":"/ai-humanoid-robotics-book/docs/tags/jetson"}],"version":"current","frontMatter":{"id":"hardware-setup","title":"Hardware Setup Guide: Building Your Physical AI Lab","sidebar_label":"Hardware Setup","description":"Complete hardware guide for Physical AI & Humanoid Robotics - From budget to premium setups","tags":["hardware","setup","guide","robotics","nvidia","jetson"]},"sidebar":"tutorialSidebar","previous":{"title":"Practical: Autonomous Humanoid","permalink":"/ai-humanoid-robotics-book/docs/module-4-vla/practical-4-autonomous-humanoid"},"next":{"title":"Cloud Lab","permalink":"/ai-humanoid-robotics-book/docs/resources/cloud-lab"}},{"id":"resources/references","title":"References & Further Reading","description":"Comprehensive bibliography of research papers, books, and resources for Physical AI and Humanoid Robotics","source":"@site/docs/resources/references.md","sourceDirName":"resources","slug":"/resources/references","permalink":"/ai-humanoid-robotics-book/docs/resources/references","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"references","permalink":"/ai-humanoid-robotics-book/docs/tags/references"},{"inline":true,"label":"bibliography","permalink":"/ai-humanoid-robotics-book/docs/tags/bibliography"},{"inline":true,"label":"research","permalink":"/ai-humanoid-robotics-book/docs/tags/research"},{"inline":true,"label":"papers","permalink":"/ai-humanoid-robotics-book/docs/tags/papers"},{"inline":true,"label":"books","permalink":"/ai-humanoid-robotics-book/docs/tags/books"}],"version":"current","frontMatter":{"id":"references","title":"References & Further Reading","sidebar_label":"References","description":"Comprehensive bibliography of research papers, books, and resources for Physical AI and Humanoid Robotics","tags":["references","bibliography","research","papers","books"]},"sidebar":"tutorialSidebar","previous":{"title":"Assessments","permalink":"/ai-humanoid-robotics-book/docs/resources/assessments"},"next":{"title":"FAQ","permalink":"/ai-humanoid-robotics-book/docs/resources/faq"}},{"id":"specifyplus/api/authentication","title":"API Authentication","description":"In the SpecifyPlus framework, \"authentication\" and \"authorization\" are handled by the ROS 2 Security features, also known as SROS2. This system provides a comprehensive security model for the robotics application, ensuring that only trusted nodes can communicate on the network.","source":"@site/docs/specifyplus/api/authentication.md","sourceDirName":"specifyplus/api","slug":"/specifyplus/api/authentication","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/api/authentication","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"specifyplus/api/endpoints","title":"API Endpoints","description":"While SpecifyPlus does not have a traditional REST or GraphQL API, its functionality is exposed through the ROS 2 graph. This document maps ROS 2 concepts to familiar API terminology. ROS 2 Topics, Services, and Actions serve as the \"endpoints\" of the system.","source":"@site/docs/specifyplus/api/endpoints.md","sourceDirName":"specifyplus/api","slug":"/specifyplus/api/endpoints","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/api/endpoints","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"specifyplus/api/rate-limiting","title":"API Rate Limiting","description":"In the context of the SpecifyPlus system and ROS 2, \"rate limiting\" and traffic shaping are managed through two primary mechanisms: the publishing rate of nodes and the Quality of Service (QoS) policies.","source":"@site/docs/specifyplus/api/rate-limiting.md","sourceDirName":"specifyplus/api","slug":"/specifyplus/api/rate-limiting","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/api/rate-limiting","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"specifyplus/architecture","title":"SpecifyPlus System Architecture","description":"This document provides a detailed look at the architecture of the SpecifyPlus system, breaking down the components and their interactions.","source":"@site/docs/specifyplus/architecture.md","sourceDirName":"specifyplus","slug":"/specifyplus/architecture","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/architecture","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"specifyplus/deployment/cloud-deployment","title":"Deployment: Cloud Deployment","description":"Deploying a full robotics stack like SpecifyPlus in the cloud presents unique challenges, particularly regarding GPU acceleration and real-time communication. This guide outlines strategies and best practices for cloud-based deployment.","source":"@site/docs/specifyplus/deployment/cloud-deployment.md","sourceDirName":"specifyplus/deployment","slug":"/specifyplus/deployment/cloud-deployment","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/deployment/cloud-deployment","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"specifyplus/deployment/local-setup","title":"Deployment: Local Setup","description":"This guide details the steps required to set up the complete SpecifyPlus development environment on a local machine. The primary target is a Linux system (Ubuntu 22.04) with a compatible NVIDIA GPU.","source":"@site/docs/specifyplus/deployment/local-setup.md","sourceDirName":"specifyplus/deployment","slug":"/specifyplus/deployment/local-setup","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/deployment/local-setup","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"specifyplus/deployment/monitoring","title":"Deployment: Monitoring","description":"Monitoring the health and performance of a complex, distributed system like SpecifyPlus is crucial for debugging, performance tuning, and ensuring reliability. The ROS 2 ecosystem provides a rich set of tools for introspection and monitoring.","source":"@site/docs/specifyplus/deployment/monitoring.md","sourceDirName":"specifyplus/deployment","slug":"/specifyplus/deployment/monitoring","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/deployment/monitoring","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"specifyplus/getting-started","title":"Getting Started with SpecifyPlus","description":"This guide will walk you through setting up a minimal SpecifyPlus environment and running a basic simulation.","source":"@site/docs/specifyplus/getting-started.md","sourceDirName":"specifyplus","slug":"/specifyplus/getting-started","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/getting-started","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"specifyplus/integration/customization","title":"Integration: Customization","description":"The SpecifyPlus framework is designed to be modular and extensible. This guide covers the most common ways to customize the system for your specific robot or application.","source":"@site/docs/specifyplus/integration/customization.md","sourceDirName":"specifyplus/integration","slug":"/specifyplus/integration/customization","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/integration/customization","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"specifyplus/integration/docusaurus","title":"Integration: Docusaurus","description":"Integrating outputs from the SpecifyPlus robotics system into a Docusaurus website can greatly enhance documentation by providing dynamic, visual content. This guide covers strategies for embedding robotics data and visualizations.","source":"@site/docs/specifyplus/integration/docusaurus.md","sourceDirName":"specifyplus/integration","slug":"/specifyplus/integration/docusaurus","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/integration/docusaurus","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"specifyplus/integration/existing-projects","title":"Integration: Existing Projects","description":"Integrating an existing robotics project with the SpecifyPlus framework primarily involves ensuring compatibility with the ROS 2 communication layer. This guide provides steps for adapting your existing ROS 1 or ROS 2 projects.","source":"@site/docs/specifyplus/integration/existing-projects.md","sourceDirName":"specifyplus/integration","slug":"/specifyplus/integration/existing-projects","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/integration/existing-projects","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"specifyplus/modules/ai-frameworks","title":"Module 3: AI Frameworks (NVIDIA Isaac)","description":"This module details the integration of NVIDIA's Isaac SDK for accelerating AI and perception tasks within the SpecifyPlus system. The Isaac ecosystem provides powerful tools for building the \"brain\" of the robot.","source":"@site/docs/specifyplus/modules/ai-frameworks.md","sourceDirName":"specifyplus/modules","slug":"/specifyplus/modules/ai-frameworks","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/modules/ai-frameworks","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"specifyplus/modules/ros2-integration","title":"Module 1: ROS 2 Integration","description":"This module documentation covers the integration of the Robotic Nervous System (ROS 2) within the SpecifyPlus framework. ROS 2 forms the communication backbone of the entire system.","source":"@site/docs/specifyplus/modules/ros2-integration.md","sourceDirName":"specifyplus/modules","slug":"/specifyplus/modules/ros2-integration","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/modules/ros2-integration","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"specifyplus/modules/simulation-tools","title":"Module 2: Simulation Tools","description":"This module covers the use of simulation tools to create a \"Digital Twin\" of the robot and its environment. Simulation is a critical part of the SpecifyPlus workflow, enabling rapid development, testing, and data generation.","source":"@site/docs/specifyplus/modules/simulation-tools.md","sourceDirName":"specifyplus/modules","slug":"/specifyplus/modules/simulation-tools","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/modules/simulation-tools","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"specifyplus/modules/vla-systems","title":"Module 4: Vision-Language-Action (VLA) Systems","description":"This module describes the highest level of the SpecifyPlus architecture, where Vision, Language, and Action are combined to create intelligent, autonomous behaviors. This layer enables natural and intuitive human-robot interaction.","source":"@site/docs/specifyplus/modules/vla-systems.md","sourceDirName":"specifyplus/modules","slug":"/specifyplus/modules/vla-systems","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/modules/vla-systems","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}},{"id":"specifyplus/overview","title":"SpecifyPlus System Overview","description":"Purpose","source":"@site/docs/specifyplus/overview.md","sourceDirName":"specifyplus","slug":"/specifyplus/overview","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/overview","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"doc","id":"intro","label":"Introduction","translatable":true},{"type":"doc","id":"prerequisites","label":"Prerequisites","translatable":true},{"type":"doc","id":"learning-path","label":"Learning Path","translatable":true},{"type":"doc","id":"hardware-guide","label":"Hardware Guide","translatable":true},{"type":"category","label":"Module 1: ROS 2","items":[{"type":"doc","id":"module-1-ros2/overview"},{"type":"doc","id":"module-1-ros2/ros2-architecture"},{"type":"doc","id":"module-1-ros2/nodes-topics-services"},{"type":"doc","id":"module-1-ros2/rclpy-python-agents"},{"type":"doc","id":"module-1-ros2/urdf-humanoids"},{"type":"doc","id":"module-1-ros2/practical-1-ros2-setup"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: Simulation","items":[{"type":"doc","id":"module-2-simulation/overview"},{"type":"doc","id":"module-2-simulation/gazebo-physics"},{"type":"doc","id":"module-2-simulation/unity-rendering"},{"type":"doc","id":"module-2-simulation/sensor-simulation"},{"type":"doc","id":"module-2-simulation/environment-building"},{"type":"doc","id":"module-2-simulation/practical-2-digital-twin"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: NVIDIA Isaac","items":[{"type":"doc","id":"module-3-isaac/overview"},{"type":"doc","id":"module-3-isaac/isaac-sim"},{"type":"doc","id":"module-3-isaac/isaac-ros"},{"type":"doc","id":"module-3-isaac/vslam-navigation"},{"type":"doc","id":"module-3-isaac/nav2-bipedal"},{"type":"doc","id":"module-3-isaac/practical-3-perception"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: VLA","items":[{"type":"doc","id":"module-4-vla/overview"},{"type":"doc","id":"module-4-vla/whisper-voice"},{"type":"doc","id":"module-4-vla/llm-planning"},{"type":"doc","id":"module-4-vla/multimodal-integration"},{"type":"doc","id":"module-4-vla/capstone-project"},{"type":"doc","id":"module-4-vla/practical-4-autonomous-humanoid"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Resources","items":[{"type":"doc","id":"resources/hardware-setup"},{"type":"doc","id":"resources/cloud-lab"},{"type":"doc","id":"resources/assessments"},{"type":"doc","id":"resources/references"},{"type":"doc","id":"resources/faq"},{"type":"doc","id":"resources/glossary"}],"collapsed":true,"collapsible":true}]}}]}},"docusaurus-plugin-content-blog":{"default":{"blogSidebarTitle":"Recent posts","blogPosts":[{"id":"welcome","metadata":{"permalink":"/ai-humanoid-robotics-book/blog/welcome","source":"@site/blog/2021-08-26-welcome/index.md","title":"Welcome","description":"Docusaurus blogging features are powered by the blog plugin.","date":"2021-08-26T00:00:00.000Z","tags":[{"inline":false,"label":"Facebook","permalink":"/ai-humanoid-robotics-book/blog/tags/facebook","description":"Facebook tag description"},{"inline":false,"label":"Hello","permalink":"/ai-humanoid-robotics-book/blog/tags/hello","description":"Hello tag description"},{"inline":false,"label":"Docusaurus","permalink":"/ai-humanoid-robotics-book/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":0.56,"hasTruncateMarker":true,"authors":[{"name":"SÃ©bastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/ai-humanoid-robotics-book/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"},{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/ai-humanoid-robotics-book/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"welcome","title":"Welcome","authors":["slorber","yangshun"],"tags":["facebook","hello","docusaurus"]},"unlisted":false,"nextItem":{"title":"MDX Blog Post","permalink":"/ai-humanoid-robotics-book/blog/mdx-blog-post"}},"content":"[Docusaurus blogging features](https://docusaurus.io/docs/blog) are powered by the [blog plugin](https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog).\n\nHere are a few tips you might find useful.\n\n<!-- truncate -->\n\nSimply add Markdown files (or folders) to the `blog` directory.\n\nRegular blog authors can be added to `authors.yml`.\n\nThe blog post date can be extracted from filenames, such as:\n\n- `2019-05-30-welcome.md`\n- `2019-05-30-welcome/index.md`\n\nA blog post folder can be convenient to co-locate blog post images:\n\n![Docusaurus Plushie](./docusaurus-plushie-banner.jpeg)\n\nThe blog supports tags as well!\n\n**And if you don't want a blog**: just delete this directory, and use `blog: false` in your Docusaurus config."},{"id":"mdx-blog-post","metadata":{"permalink":"/ai-humanoid-robotics-book/blog/mdx-blog-post","source":"@site/blog/2021-08-01-mdx-blog-post.mdx","title":"MDX Blog Post","description":"Blog posts support Docusaurus Markdown features, such as MDX.","date":"2021-08-01T00:00:00.000Z","tags":[{"inline":false,"label":"Docusaurus","permalink":"/ai-humanoid-robotics-book/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":0.27,"hasTruncateMarker":true,"authors":[{"name":"SÃ©bastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/ai-humanoid-robotics-book/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"}],"frontMatter":{"slug":"mdx-blog-post","title":"MDX Blog Post","authors":["slorber"],"tags":["docusaurus"]},"unlisted":false,"prevItem":{"title":"Welcome","permalink":"/ai-humanoid-robotics-book/blog/welcome"},"nextItem":{"title":"Long Blog Post","permalink":"/ai-humanoid-robotics-book/blog/long-blog-post"}},"content":"Blog posts support [Docusaurus Markdown features](https://docusaurus.io/docs/markdown-features), such as [MDX](https://mdxjs.com/).\n\n:::tip\n\nUse the power of React to create interactive blog posts.\n\n:::\n\n{/* truncate */}\n\nFor example, use JSX to create an interactive button:\n\n```js\n<button onClick={() => alert('button clicked!')}>Click me!</button>\n```\n\n<button onClick={() => alert('button clicked!')}>Click me!</button>"},{"id":"long-blog-post","metadata":{"permalink":"/ai-humanoid-robotics-book/blog/long-blog-post","source":"@site/blog/2019-05-29-long-blog-post.md","title":"Long Blog Post","description":"This is the summary of a very long blog post,","date":"2019-05-29T00:00:00.000Z","tags":[{"inline":false,"label":"Hello","permalink":"/ai-humanoid-robotics-book/blog/tags/hello","description":"Hello tag description"},{"inline":false,"label":"Docusaurus","permalink":"/ai-humanoid-robotics-book/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":2.04,"hasTruncateMarker":true,"authors":[{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/ai-humanoid-robotics-book/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"long-blog-post","title":"Long Blog Post","authors":"yangshun","tags":["hello","docusaurus"]},"unlisted":false,"prevItem":{"title":"MDX Blog Post","permalink":"/ai-humanoid-robotics-book/blog/mdx-blog-post"},"nextItem":{"title":"First Blog Post","permalink":"/ai-humanoid-robotics-book/blog/first-blog-post"}},"content":"This is the summary of a very long blog post,\n\nUse a `<!--` `truncate` `-->` comment to limit blog post size in the list view.\n\n<!-- truncate -->\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"},{"id":"first-blog-post","metadata":{"permalink":"/ai-humanoid-robotics-book/blog/first-blog-post","source":"@site/blog/2019-05-28-first-blog-post.md","title":"First Blog Post","description":"Lorem ipsum dolor sit amet...","date":"2019-05-28T00:00:00.000Z","tags":[{"inline":false,"label":"Hola","permalink":"/ai-humanoid-robotics-book/blog/tags/hola","description":"Hola tag description"},{"inline":false,"label":"Docusaurus","permalink":"/ai-humanoid-robotics-book/blog/tags/docusaurus","description":"Docusaurus tag description"}],"readingTime":0.13,"hasTruncateMarker":true,"authors":[{"name":"SÃ©bastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/ai-humanoid-robotics-book/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"},{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/ai-humanoid-robotics-book/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"first-blog-post","title":"First Blog Post","authors":["slorber","yangshun"],"tags":["hola","docusaurus"]},"unlisted":false,"prevItem":{"title":"Long Blog Post","permalink":"/ai-humanoid-robotics-book/blog/long-blog-post"}},"content":"Lorem ipsum dolor sit amet...\n\n<!-- truncate -->\n\n...consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"}],"blogListPaginated":[{"items":["welcome","mdx-blog-post","long-blog-post","first-blog-post"],"metadata":{"permalink":"/ai-humanoid-robotics-book/blog","page":1,"postsPerPage":10,"totalPages":1,"totalCount":4,"blogDescription":"Blog","blogTitle":"Blog"}}],"blogTags":{"/ai-humanoid-robotics-book/blog/tags/facebook":{"inline":false,"label":"Facebook","permalink":"/ai-humanoid-robotics-book/blog/tags/facebook","description":"Facebook tag description","items":["welcome"],"pages":[{"items":["welcome"],"metadata":{"permalink":"/ai-humanoid-robotics-book/blog/tags/facebook","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/ai-humanoid-robotics-book/blog/tags/hello":{"inline":false,"label":"Hello","permalink":"/ai-humanoid-robotics-book/blog/tags/hello","description":"Hello tag description","items":["welcome","long-blog-post"],"pages":[{"items":["welcome","long-blog-post"],"metadata":{"permalink":"/ai-humanoid-robotics-book/blog/tags/hello","page":1,"postsPerPage":10,"totalPages":1,"totalCount":2,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/ai-humanoid-robotics-book/blog/tags/docusaurus":{"inline":false,"label":"Docusaurus","permalink":"/ai-humanoid-robotics-book/blog/tags/docusaurus","description":"Docusaurus tag description","items":["welcome","mdx-blog-post","long-blog-post","first-blog-post"],"pages":[{"items":["welcome","mdx-blog-post","long-blog-post","first-blog-post"],"metadata":{"permalink":"/ai-humanoid-robotics-book/blog/tags/docusaurus","page":1,"postsPerPage":10,"totalPages":1,"totalCount":4,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/ai-humanoid-robotics-book/blog/tags/hola":{"inline":false,"label":"Hola","permalink":"/ai-humanoid-robotics-book/blog/tags/hola","description":"Hola tag description","items":["first-blog-post"],"pages":[{"items":["first-blog-post"],"metadata":{"permalink":"/ai-humanoid-robotics-book/blog/tags/hola","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false}},"blogTagsListPath":"/ai-humanoid-robotics-book/blog/tags","authorsMap":{"yangshun":{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/ai-humanoid-robotics-book/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"},"slorber":{"name":"SÃ©bastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/ai-humanoid-robotics-book/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"}}}},"docusaurus-plugin-content-pages":{"default":[{"type":"jsx","permalink":"/ai-humanoid-robotics-book/background-assessment","source":"@site/src/pages/background-assessment.js"},{"type":"jsx","permalink":"/ai-humanoid-robotics-book/chatbot","source":"@site/src/pages/chatbot.js"},{"type":"jsx","permalink":"/ai-humanoid-robotics-book/dashboard","source":"@site/src/pages/dashboard.js"},{"type":"jsx","permalink":"/ai-humanoid-robotics-book/","source":"@site/src/pages/index.tsx"},{"type":"jsx","permalink":"/ai-humanoid-robotics-book/login","source":"@site/src/pages/login.js"},{"type":"mdx","permalink":"/ai-humanoid-robotics-book/markdown-page","source":"@site/src/pages/markdown-page.md","title":"Markdown page example","description":"You don't need React to write simple standalone pages.","frontMatter":{"title":"Markdown page example"},"unlisted":false},{"type":"jsx","permalink":"/ai-humanoid-robotics-book/profile-manager","source":"@site/src/pages/profile-manager.js"},{"type":"jsx","permalink":"/ai-humanoid-robotics-book/signup","source":"@site/src/pages/signup.js"}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-plugin-dotenv":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}