"use strict";(globalThis.webpackChunkai_humanoid_robotics_book_new=globalThis.webpackChunkai_humanoid_robotics_book_new||[]).push([[6516],{2052:(e,s,a)=>{a.r(s),a.d(s,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>t,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"specifyplus/modules/ai-frameworks","title":"Module 3: AI Frameworks (NVIDIA Isaac)","description":"This module details the integration of NVIDIA\'s Isaac SDK for accelerating AI and perception tasks within the SpecifyPlus system. The Isaac ecosystem provides powerful tools for building the \\"brain\\" of the robot.","source":"@site/docs/specifyplus/modules/ai-frameworks.md","sourceDirName":"specifyplus/modules","slug":"/specifyplus/modules/ai-frameworks","permalink":"/ai-humanoid-robotics-book/docs/specifyplus/modules/ai-frameworks","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}}');var i=a(4848),o=a(8453);const t={},r="Module 3: AI Frameworks (NVIDIA Isaac)",l={},c=[{value:"NVIDIA Isaac Sim",id:"nvidia-isaac-sim",level:2},{value:"Isaac ROS",id:"isaac-ros",level:2},{value:"VSLAM Navigation",id:"vslam-navigation",level:2},{value:"Nav2 for Bipedal Robots",id:"nav2-for-bipedal-robots",level:2}];function d(e){const s={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"module-3-ai-frameworks-nvidia-isaac",children:"Module 3: AI Frameworks (NVIDIA Isaac)"})}),"\n",(0,i.jsx)(s.p,{children:'This module details the integration of NVIDIA\'s Isaac SDK for accelerating AI and perception tasks within the SpecifyPlus system. The Isaac ecosystem provides powerful tools for building the "brain" of the robot.'}),"\n",(0,i.jsx)(s.h2,{id:"nvidia-isaac-sim",children:"NVIDIA Isaac Sim"}),"\n",(0,i.jsx)(s.p,{children:"Isaac Sim is a robotics simulation platform built on NVIDIA Omniverse. It offers several advantages that are key to the SpecifyPlus workflow:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Photorealistic Rendering:"})," High-fidelity, ray-traced rendering is crucial for training and testing vision-based AI models."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"GPU-Accelerated Physics:"})," Isaac Sim leverages the GPU to run physics simulations, enabling large-scale, complex environments and faster-than-real-time simulation."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"ROS 2 Integration:"})," It has built-in support for connecting to the ROS 2 graph, allowing seamless integration with the rest of the SpecifyPlus system. It can subscribe to commands and publish sensor data just like Gazebo."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Synthetic Data Generation:"})," Provides advanced tools for generating labeled synthetic data for training perception algorithms."]}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"isaac-ros",children:"Isaac ROS"}),"\n",(0,i.jsx)(s.p,{children:"Isaac ROS is a collection of ROS 2 packages that are hardware-accelerated using NVIDIA's GPU technologies (CUDA, TensorRT). SpecifyPlus utilizes these packages to offload heavy computation from the CPU and achieve high performance."}),"\n",(0,i.jsx)(s.p,{children:"Key Isaac ROS packages used in the system:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsxs)(s.strong,{children:[(0,i.jsx)(s.code,{children:"isaac_ros_vslam"}),":"]})," Provides a high-performance Visual SLAM pipeline that uses the robot's camera and IMU to create a map and track the robot's pose."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsxs)(s.strong,{children:[(0,i.jsx)(s.code,{children:"isaac_ros_apriltag"}),":"]})," For detecting and tracking AprilTags, which are often used for localization or object identification."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsxs)(s.strong,{children:[(0,i.jsx)(s.code,{children:"isaac_ros_stereo_image_proc"}),":"]})," Computes disparity and point clouds from a stereo camera feed, accelerated on the GPU."]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Example: VSLAM Data Flow"})}),"\n",(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-mermaid",children:"graph TD\r\n    A[Camera Node] --\x3e|/camera/image_raw| B[isaac_ros_vslam];\r\n    C[IMU Node] --\x3e|/imu/data| B;\r\n    B --\x3e|/tf| D[Transform Tree];\r\n    B --\x3e|/map| E[Map Server];\n"})}),"\n",(0,i.jsx)(s.h2,{id:"vslam-navigation",children:"VSLAM Navigation"}),"\n",(0,i.jsxs)(s.p,{children:["Visual Simultaneous Localization and Mapping (VSLAM) is a core capability of the SpecifyPlus system. By using the ",(0,i.jsx)(s.code,{children:"isaac_ros_vslam"})," package, the robot can navigate in unknown environments."]}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Input:"})," The VSLAM node takes in synchronized camera images and IMU data."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Processing:"})," It identifies and tracks visual features across image frames. The IMU data helps to predict motion between frames."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Output:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["It publishes the robot's estimated position and orientation to the ROS 2 transform tree (",(0,i.jsx)(s.code,{children:"/tf"}),")."]}),"\n",(0,i.jsx)(s.li,{children:"It builds and publishes a map of the environment."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"This pose information is then used by the navigation stack to plan paths."}),"\n",(0,i.jsx)(s.h2,{id:"nav2-for-bipedal-robots",children:"Nav2 for Bipedal Robots"}),"\n",(0,i.jsx)(s.p,{children:"The standard ROS 2 Navigation Stack (Nav2) is used for path planning and obstacle avoidance. While Nav2 is typically used for wheeled robots, it is adapted in SpecifyPlus for bipedal locomotion."}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Global Planner:"})," The global planner in Nav2 (e.g., SmacPlanner) creates a high-level path from the robot's current location to a goal, avoiding obstacles based on the map created by VSLAM."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Local Planner / Controller:"})," The standard local planners (e.g., DWB, TEB) are replaced with a custom bipedal motion controller. This controller receives the global path and is responsible for executing the walking gait to follow that path, while also handling real-time obstacle avoidance using local sensor data (like LiDAR)."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Inputs:"})," The Nav2 stack takes the map from the VSLAM system and the robot's pose."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Output:"})," It produces velocity commands (",(0,i.jsx)(s.code,{children:"/cmd_vel"}),") that are consumed by the bipedal walking controller."]}),"\n"]})]})}function h(e={}){const{wrapper:s}={...(0,o.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,s,a)=>{a.d(s,{R:()=>t,x:()=>r});var n=a(6540);const i={},o=n.createContext(i);function t(e){const s=n.useContext(o);return n.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function r(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),n.createElement(o.Provider,{value:s},e.children)}}}]);